{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import necessary python modules\n",
    "from scipy.io import loadmat\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import binarize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "#load spam data\n",
    "matObject = loadmat('spamData.mat')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "#read original arrays from .mat file\n",
    "xTrainOrig = matObject['Xtrain']\n",
    "yTrainOrig = matObject['ytrain']\n",
    "xTestOrig = matObject['Xtest']\n",
    "yTestOrig = matObject['ytest']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "#binarize feature data\n",
    "xTrainLog = np.log(xTrainOrig+0.1)\n",
    "xTestLog = np.log(xTestOrig+0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "#flatten the label data\n",
    "yTrainFlat = yTrainOrig.flatten()\n",
    "yTestFlat = yTestOrig.flatten()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Test the implementation with minimum data\n",
    "#xTrainLog = xTrainLog[0:1000]\n",
    "#yTrainFlat = yTrainFlat[0:1000]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-2.30258509, -2.30258509, -2.30258509, ...,  1.22495121,\n",
       "         3.87328218,  4.33204826],\n",
       "       [-2.30258509, -2.30258509, -2.30258509, ...,  2.89325648,\n",
       "         5.29881724,  5.9325104 ],\n",
       "       [-2.30258509, -0.40047757, -0.40047757, ...,  0.40145709,\n",
       "         1.80828877,  5.06953294],\n",
       "       ...,\n",
       "       [-2.30258509, -2.30258509, -2.30258509, ...,  0.95551145,\n",
       "         2.71469474,  4.17592455],\n",
       "       [-0.71334989, -2.30258509, -1.23787436, ...,  0.7889118 ,\n",
       "         2.83907846,  5.7401144 ],\n",
       "       [-2.30258509, -2.30258509, -2.30258509, ...,  0.09531018,\n",
       "         0.09531018,  1.62924054]])"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xTrainLog"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 1, ..., 0, 0, 0], dtype=uint8)"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "yTrainFlat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = [0,1]\n",
    "training_results = []\n",
    "test_results = []\n",
    "train_accuracy = []\n",
    "test_accuracy = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculateML(label):\n",
    "    return np.log(list(yTrainFlat).count(label)/len(yTrainFlat))\n",
    "\n",
    "def calculateSecondTerm(feature,xStd,xMean):\n",
    "    return -np.log(xStd) - ((feature - xMean)/xStd) ** 2 / 2\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "def classify(row):\n",
    "    probList = []\n",
    "    for labelIndex,label in enumerate(labels):\n",
    "        probLabel = lambdaLabels[labelIndex]\n",
    "        for index, feature in enumerate(row):\n",
    "            xMean = MeanList[labelIndex][index]\n",
    "            xStd  = StdList[labelIndex][index]\n",
    "            probLabel += calculateSecondTerm(feature,xStd,xMean)\n",
    "        probList.append(probLabel)\n",
    "    #print(probList)\n",
    "    return (labels[probList.index(max(probList))])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "FL_list = []\n",
    "lambdaLabels = []\n",
    "labelCounts = []\n",
    "MeanList = []\n",
    "StdList = []\n",
    "\n",
    "for labelIndex,label in enumerate(labels):\n",
    "    MeanList.append(xTrainLog[yTrainFlat==label].mean(axis=0))\n",
    "    StdList.append(xTrainLog[yTrainFlat==label].std(axis=0))\n",
    "    lambdaLabels.append(calculateML(label))\n",
    "    labelCounts.append(list(yTrainFlat).count(label))\n",
    "    \n",
    "training_results = []\n",
    "test_results = []\n",
    "\n",
    "for index,row in enumerate(xTrainLog):\n",
    "    training_results.append(classify(row))\n",
    "\n",
    "training_results = np.asarray(training_results)\n",
    "train_accuracy.append(np.sum(yTrainFlat == training_results))\n",
    "\n",
    "for index,row in enumerate(xTestLog):\n",
    "    test_results.append(classify(row))\n",
    "\n",
    "test_results = np.asarray(test_results)\n",
    "test_accuracy.append(np.sum(yTestFlat == test_results))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training error\t:  [16.802610114192497] %\n",
      "Test error \t:  [16.341145833333336] %\n"
     ]
    }
   ],
   "source": [
    "totalTrainMails = len(yTrainFlat)\n",
    "train_accuracy[:] = [(1-x/totalTrainMails)*100 for x in train_accuracy]\n",
    "\n",
    "totalTestMails = len(yTestFlat)\n",
    "test_accuracy[:] = [(1-x/totalTestMails)*100 for x in test_accuracy]\n",
    "\n",
    "print (\"Training error\\t: \", train_accuracy,\"%\")\n",
    "print (\"Test error \\t: \", test_accuracy,\"%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
